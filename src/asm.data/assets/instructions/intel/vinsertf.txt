00144384:VINSERTF128/VINSERTF32x4/VINSERTF64x2/VINSERTF32x8/VINSERTF64x4—Insert Packed Floating-Point Values
00144385:INSTRUCTION SET REFERENCE, V-Z
00144386:5-288 Vol. 2C
00144387:VINSERTF128/VINSERTF32x4/VINSERTF64x2/VINSERTF32x8/VINSERTF64x4—Insert Packed
00144388:Floating-Point Values
00144389:Instruction Operand Encoding
00144390:Description
00144391:VINSERTF128/VINSERTF32x4 and VINSERTF64x2 insert 128-bits of packed floating-point values from the second
00144392:source operand (the third operand) into the destination operand (the first operand) at an 128-bit granularity offset
00144393:multiplied by imm8[0] (256-bit) or imm8[1:0]. The remaining portions of the destination operand are copied from
00144394:the corresponding fields of the first source operand (the second operand). The second source operand can be either
00144395:an XMM register or a 128-bit memory location. The destination and first source operands are vector registers.
00144396:VINSERTF32x4: The destination operand is a ZMM/YMM register and updated at 32-bit granularity according to the
00144397:writemask. The high 6/7 bits of the immediate are ignored.
00144398:VINSERTF64x2: The destination operand is a ZMM/YMM register and updated at 64-bit granularity according to the
00144399:writemask. The high 6/7 bits of the immediate are ignored.
00144400:VINSERTF32x8 and VINSERTF64x4 inserts 256-bits of packed floating-point values from the second source operand
00144401:(the third operand) into the destination operand (the first operand) at a 256-bit granular offset multiplied by
00144402:imm8[0]. The remaining portions of the destination are copied from the corresponding fields of the first source
00144403:operand (the second operand). The second source operand can be either an YMM register or a 256-bit memory
00144404:location. The high 7 bits of the immediate are ignored. The destination operand is a ZMM register and updated at
00144405:32/64-bit granularity according to the writemask.
00144406:Opcode/
00144407:Instruction
00144408:Op /
00144409:En
00144410:64/32
00144411:bit Mode
00144412:Support
00144413:CPUID
00144414:Feature
00144415:Flag
00144416:Description
00144417:VEX.256.66.0F3A.W0 18 /r ib
00144418:VINSERTF128 ymm1, ymm2,
00144419:xmm3/m128, imm8
00144420:A
00144421:V/V
00144422:AVX
00144423:Insert 128 bits of packed floating-point values from
00144424:xmm3/m128 and the remaining values from ymm2
00144425:into ymm1.
00144426:EVEX.256.66.0F3A.W0 18 /r ib
00144427:VINSERTF32X4 ymm1 {k1}{z}, ymm2,
00144428:xmm3/m128, imm8
00144429:C
00144430:V/V
00144431:AVX512VL
00144432:AVX512F
00144433:Insert 128 bits of packed single-precision floating-
00144434:point values from xmm3/m128 and the remaining
00144435:values from ymm2 into ymm1 under writemask k1.
00144436:EVEX.512.66.0F3A.W0 18 /r ib
00144437:VINSERTF32X4 zmm1 {k1}{z}, zmm2,
00144438:xmm3/m128, imm8
00144439:C
00144440:V/V
00144441:AVX512F
00144442:Insert 128 bits of packed single-precision floating-
00144443:point values from xmm3/m128 and the remaining
00144444:values from zmm2 into zmm1 under writemask k1.
00144445:EVEX.256.66.0F3A.W1 18 /r ib
00144446:VINSERTF64X2 ymm1 {k1}{z}, ymm2,
00144447:xmm3/m128, imm8
00144448:B
00144449:V/V
00144450:AVX512VL
00144451:AVX512DQ
00144452:Insert 128 bits of packed double-precision floating-
00144453:point values from xmm3/m128 and the remaining
00144454:values from ymm2 into ymm1 under writemask k1.
00144455:EVEX.512.66.0F3A.W1 18 /r ib
00144456:VINSERTF64X2 zmm1 {k1}{z}, zmm2,
00144457:xmm3/m128, imm8
00144458:B
00144459:V/V
00144460:AVX512DQ
00144461:Insert 128 bits of packed double-precision floating-
00144462:point values from xmm3/m128 and the remaining
00144463:values from zmm2 into zmm1 under writemask k1.
00144464:EVEX.512.66.0F3A.W0 1A /r ib
00144465:VINSERTF32X8 zmm1 {k1}{z}, zmm2,
00144466:ymm3/m256, imm8
00144467:D
00144468:V/V
00144469:AVX512DQ
00144470:Insert 256 bits of packed single-precision floating-
00144471:point values from ymm3/m256 and the remaining
00144472:values from zmm2 into zmm1 under writemask k1.
00144473:EVEX.512.66.0F3A.W1 1A /r ib
00144474:VINSERTF64X4 zmm1 {k1}{z}, zmm2,
00144475:ymm3/m256, imm8
00144476:C
00144477:V/V
00144478:AVX512F
00144479:Insert 256 bits of packed double-precision floating-
00144480:point values from ymm3/m256 and the remaining
00144481:values from zmm2 into zmm1 under writemask k1.
00144482:Op/En
00144483:Tuple Type
00144484:Operand 1
00144485:Operand 2
00144486:Operand 3
00144487:Operand 4
00144488:A
00144489:NA
00144490:ModRM:reg (w)
00144491:VEX.vvvv
00144492:ModRM:r/m (r)
00144493:Imm8
00144494:B
00144495:Tuple2
00144496:ModRM:reg (w)
00144497:EVEX.vvvv
00144498:ModRM:r/m (r)
00144499:Imm8
00144500:C
00144501:Tuple4
00144502:ModRM:reg (w)
00144503:EVEX.vvvv
00144504:ModRM:r/m (r)
00144505:Imm8
00144506:D
00144507:Tuple8
00144508:ModRM:reg (w)
00144509:EVEX.vvvv
00144510:ModRM:r/m (r)
00144511:Imm8
00144512:VINSERTF128/VINSERTF32x4/VINSERTF64x2/VINSERTF32x8/VINSERTF64x4—Insert Packed Floating-Point Values
00144513:INSTRUCTION SET REFERENCE, V-Z
00144514:Vol. 2C 5-289
00144515:Operation
00144516:VINSERTF32x4 (EVEX encoded versions)
00144517:(KL, VL) = (8, 256), (16, 512)
00144518:TEMP_DEST[VL-1:0] := SRC1[VL-1:0]
00144519:IF VL = 256
00144520:CASE (imm8[0]) OF
00144521:0:
00144522:TMP_DEST[127:0] := SRC2[127:0]
00144523:1:
00144524:TMP_DEST[255:128] := SRC2[127:0]
00144525:ESAC.
00144526:FI;
00144527:IF VL = 512
00144528:CASE (imm8[1:0]) OF
00144529:00: TMP_DEST[127:0] := SRC2[127:0]
00144530:01: TMP_DEST[255:128] := SRC2[127:0]
00144531:10: TMP_DEST[383:256] := SRC2[127:0]
00144532:11: TMP_DEST[511:384] := SRC2[127:0]
00144533:ESAC.
00144534:FI;
00144535:FOR j := 0 TO KL-1
00144536:i := j * 32
00144537:IF k1[j] OR *no writemask*
00144538:THEN DEST[i+31:i] := TMP_DEST[i+31:i]
00144539:ELSE
00144540:IF *merging-masking*
00144541:; merging-masking
00144542:THEN *DEST[i+31:i] remains unchanged*
00144543:ELSE
00144544:; zeroing-masking
00144545:DEST[i+31:i] := 0
00144546:FI
00144547:FI;
00144548:ENDFOR
00144549:DEST[MAXVL-1:VL] := 0
00144550:VINSERTF64x2 (EVEX encoded versions)
00144551:(KL, VL) = (4, 256), (8, 512)
00144552:TEMP_DEST[VL-1:0] := SRC1[VL-1:0]
00144553:IF VL = 256
00144554:CASE (imm8[0]) OF
00144555:0:
00144556:TMP_DEST[127:0] := SRC2[127:0]
00144557:1:
00144558:TMP_DEST[255:128] := SRC2[127:0]
00144559:ESAC.
00144560:FI;
00144561:IF VL = 512
00144562:CASE (imm8[1:0]) OF
00144563:00: TMP_DEST[127:0] := SRC2[127:0]
00144564:01: TMP_DEST[255:128] := SRC2[127:0]
00144565:10: TMP_DEST[383:256] := SRC2[127:0]
00144566:11: TMP_DEST[511:384] := SRC2[127:0]
00144567:ESAC.
00144568:FI;
00144569:FOR j := 0 TO KL-1
00144570:i := j * 64
00144571:IF k1[j] OR *no writemask*
00144572:THEN DEST[i+63:i] := TMP_DEST[i+63:i]
00144573:ELSE
00144574:VINSERTF128/VINSERTF32x4/VINSERTF64x2/VINSERTF32x8/VINSERTF64x4—Insert Packed Floating-Point Values
00144575:INSTRUCTION SET REFERENCE, V-Z
00144576:5-290 Vol. 2C
00144577:IF *merging-masking*
00144578:; merging-masking
00144579:THEN *DEST[i+63:i] remains unchanged*
00144580:ELSE
00144581:; zeroing-masking
00144582:DEST[i+63:i] := 0
00144583:FI
00144584:FI;
00144585:ENDFOR
00144586:DEST[MAXVL-1:VL] := 0
00144587:VINSERTF32x8 (EVEX.U1.512 encoded version)
00144588:TEMP_DEST[VL-1:0] := SRC1[VL-1:0]
00144589:CASE (imm8[0]) OF
00144590:0: TMP_DEST[255:0] := SRC2[255:0]
00144591:1: TMP_DEST[511:256] := SRC2[255:0]
00144592:ESAC.
00144593:FOR j := 0 TO 15
00144594:i := j * 32
00144595:IF k1[j] OR *no writemask*
00144596:THEN DEST[i+31:i] := TMP_DEST[i+31:i]
00144597:ELSE
00144598:IF *merging-masking*
00144599:; merging-masking
00144600:THEN *DEST[i+31:i] remains unchanged*
00144601:ELSE
00144602:; zeroing-masking
00144603:DEST[i+31:i] := 0
00144604:FI
00144605:FI;
00144606:ENDFOR
00144607:DEST[MAXVL-1:VL] := 0
00144608:VINSERTF64x4 (EVEX.512 encoded version)
00144609:VL = 512
00144610:TEMP_DEST[VL-1:0] := SRC1[VL-1:0]
00144611:CASE (imm8[0]) OF
00144612:0: TMP_DEST[255:0] := SRC2[255:0]
00144613:1: TMP_DEST[511:256] := SRC2[255:0]
00144614:ESAC.
00144615:FOR j := 0 TO 7
00144616:i := j * 64
00144617:IF k1[j] OR *no writemask*
00144618:THEN DEST[i+63:i] := TMP_DEST[i+63:i]
00144619:ELSE
00144620:IF *merging-masking*
00144621:; merging-masking
00144622:THEN *DEST[i+63:i] remains unchanged*
00144623:ELSE
00144624:; zeroing-masking
00144625:DEST[i+63:i] := 0
00144626:FI
00144627:FI;
00144628:ENDFOR
00144629:DEST[MAXVL-1:VL] := 0
00144630:VINSERTF128/VINSERTF32x4/VINSERTF64x2/VINSERTF32x8/VINSERTF64x4—Insert Packed Floating-Point Values
00144631:INSTRUCTION SET REFERENCE, V-Z
00144632:Vol. 2C 5-291
00144633:VINSERTF128 (VEX encoded version)
00144634:TEMP[255:0] := SRC1[255:0]
00144635:CASE (imm8[0]) OF
00144636:0: TEMP[127:0] := SRC2[127:0]
00144637:1: TEMP[255:128] := SRC2[127:0]
00144638:ESAC
00144639:DEST := TEMP
00144640:Intel C/C++ Compiler Intrinsic Equivalent
00144641:VINSERTF32x4 __m512 _mm512_insertf32x4( __m512 a, __m128 b, int imm);
00144642:VINSERTF32x4 __m512 _mm512_mask_insertf32x4(__m512 s, __mmask16 k, __m512 a, __m128 b, int imm);
00144643:VINSERTF32x4 __m512 _mm512_maskz_insertf32x4( __mmask16 k, __m512 a, __m128 b, int imm);
00144644:VINSERTF32x4 __m256 _mm256_insertf32x4( __m256 a, __m128 b, int imm);
00144645:VINSERTF32x4 __m256 _mm256_mask_insertf32x4(__m256 s, __mmask8 k, __m256 a, __m128 b, int imm);
00144646:VINSERTF32x4 __m256 _mm256_maskz_insertf32x4( __mmask8 k, __m256 a, __m128 b, int imm);
00144647:VINSERTF32x8 __m512 _mm512_insertf32x8( __m512 a, __m256 b, int imm);
00144648:VINSERTF32x8 __m512 _mm512_mask_insertf32x8(__m512 s, __mmask16 k, __m512 a, __m256 b, int imm);
00144649:VINSERTF32x8 __m512 _mm512_maskz_insertf32x8( __mmask16 k, __m512 a, __m256 b, int imm);
00144650:VINSERTF64x2 __m512d _mm512_insertf64x2( __m512d a, __m128d b, int imm);
00144651:VINSERTF64x2 __m512d _mm512_mask_insertf64x2(__m512d s, __mmask8 k, __m512d a, __m128d b, int imm);
00144652:VINSERTF64x2 __m512d _mm512_maskz_insertf64x2( __mmask8 k, __m512d a, __m128d b, int imm);
00144653:VINSERTF64x2 __m256d _mm256_insertf64x2( __m256d a, __m128d b, int imm);
00144654:VINSERTF64x2 __m256d _mm256_mask_insertf64x2(__m256d s, __mmask8 k, __m256d a, __m128d b, int imm);
00144655:VINSERTF64x2 __m256d _mm256_maskz_insertf64x2( __mmask8 k, __m256d a, __m128d b, int imm);
00144656:VINSERTF64x4 __m512d _mm512_insertf64x4( __m512d a, __m256d b, int imm);
00144657:VINSERTF64x4 __m512d _mm512_mask_insertf64x4(__m512d s, __mmask8 k, __m512d a, __m256d b, int imm);
00144658:VINSERTF64x4 __m512d _mm512_maskz_insertf64x4( __mmask8 k, __m512d a, __m256d b, int imm);
00144659:VINSERTF128 __m256 _mm256_insertf128_ps (__m256 a, __m128 b, int offset);
00144660:VINSERTF128 __m256d _mm256_insertf128_pd (__m256d a, __m128d b, int offset);
00144661:VINSERTF128 __m256i _mm256_insertf128_si256 (__m256i a, __m128i b, int offset);
00144662:SIMD Floating-Point Exceptions
00144663:None
00144664:Other Exceptions
00144665:VEX-encoded instruction, see Exceptions Type 6; additionally
00144666:#UD
00144667:If VEX.L = 0.
00144668:EVEX-encoded instruction, see Exceptions Type E6NF.
